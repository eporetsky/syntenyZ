{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blastdbcmd tutorial\n",
    "#https://blastedbio.blogspot.com/2012/10/my-ids-not-good-enough-for-ncbi-blast.html\n",
    "\n",
    "import os, sys, pathlib\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"GeneID\"\n",
    "#os.chdir(r\"C:\\Users\\SagerFish\\Dropbox\\Git\\syntenyZ\") # For windows\n",
    "os.chdir(\"/Users/eporetsky/Dropbox/Git/syntenyZ\")    # For max, linux\n",
    "pathlib.Path(project_name+\"/\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_loci\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/fasta_loci\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_loci\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_CDS\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_CDS/genes\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_CDS/inbreds\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_intergenic\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_intergenic/genes\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_intergenic/inbreds\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dictionary with taxa title ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary of the taxa ID csv based on the blast DB based on a custom csv file\n",
    "# For each taxa ID returns a dictionaty key:val like this: '1': 'B73', '2': 'W22' ... \n",
    "taxa_dict = {}\n",
    "title2taxa = open(\"../FASTA/title2taxa.csv\",\"r\")\n",
    "for line in title2taxa:\n",
    "    line = line.strip().split(\",\") # strip remove \\n from the end\n",
    "    taxa_dict[line[1]] = line[0]   # add the lines as a new dicrionary element\n",
    "# I don't know why it started adding wrong UNICODE encoding to B73 ('\\ufeffB73')\n",
    "taxa_dict[\"1\"] = \"B73\"\n",
    "taxa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BlastDB doesn't retain the origin chromsome numbers so I manually made a conversion list\n",
    "# returns a dict like this: 'B73', 'Chr10'): 'gnl|BL_ORD_ID|0', ('B73', 'Chr1'): 'gnl|BL_ORD_ID|1' ...\n",
    "\n",
    "# I don't know why it started adding wrong UNICODE encoding to B73 ('\\ufeffB73')\n",
    "# Had to add the stupid count and manually change the first row\n",
    "count = 0\n",
    "\n",
    "identity_dict = {}\n",
    "chr2identity = open(\"../FASTA/chr2identity.csv\",\"r\")\n",
    "for line in chr2identity:\n",
    "    if count==0:\n",
    "        identity_dict[(\"title\",\"chr\",)] = \"identity\" # add values to tuple keys\n",
    "    else:\n",
    "        line = line.strip().split(\",\")            # strip remove \\n from the end\n",
    "        identity_dict[tuple(line[0:2])] = line[2] # add values to tuple keys\n",
    "    count += 1\n",
    "identity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to make a function to merge overlapping exons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to try to predict tandem duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Really short sequences don't return a blast result: 6a_CTX_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run blast on specified genomes using the query.fasta in the project file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#os.chdir(r\"C:\\Users\\SagerFish\\Dropbox\\Git\\FASTA\\BLASTdb\") # For windows\n",
    "os.chdir(\"/Users/eporetsky/Dropbox/Git/FASTA/BLASTdb/\")   # For mac, linux\n",
    "\n",
    "# Before running blastn to get target hits, make sure that you have the query.fasta file in your project folder\n",
    "\n",
    "print(\"Changed directory to:\", os.getcwd())\n",
    "# This used to work but one day it stopped working. Now when I run blasn with multiple db files it doesn't report staxid accurately, as in - almost all of the results are the same \"1\"\n",
    "#os.system('blastn -db \"B73.db W22.db Mo17.db B97.db CML52.db CML103.db CML228.db CML247.db CML277.db CML322.db CML333.db CML69.db EP1.db F7.db HP301.db Il14H.db Ki11.db Ki3.db Ky21.db M162W.db M37W.db Mo18W.db Ms71.db NC350.db NC358.db Oh43.db Oh7B.db P39.db Tx303.db Tzi8.db PI566673.db\" -query ../../syntenyZ/'+project_name+'/query.fasta -out ../../syntenyZ/'+project_name+'/blast_results.tsv -num_threads 4 -evalue 1e-4 -outfmt \"6 staxid qseqid qstart qend sseqid sstart send\"')\n",
    "for i in range(1,32):\n",
    "    os.system('blastn -db '+taxa_dict[str(i)]+'.db -query ../../syntenyZ/'+project_name+'/query.fasta -num_threads 4 -evalue 1e-4 -outfmt \"6 staxid qseqid qstart qend sseqid sstart send\" >> ../../syntenyZ/'+project_name+'/blast_results.tsv')\n",
    "os.chdir(\"../../syntenyZ/\"+project_name+\"/\")\n",
    "print(\"Changed directory back to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before continuing, filter the blast results to contain only wanted rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(project_name+\"/\")\n",
    "blast_df = pd.read_table(\"blast_results.tsv\", header=None, names=[\"taxa\",\"ref\", \"qs\",\"qe\",\"chr\",\"ss\",\"se\"])\n",
    "blast_df['strand'] = blast_df[['ss','se']].apply(lambda x: \"+\" if x['ss']<x['se'] else \"-\", axis=1)\n",
    "#blast_df = blast_df[blast_df[\"taxa\"]==1]\n",
    "blast_tolist = blast_df.sort_values(['taxa', 'chr', 'ss',  ], ascending=[True, True, True]).values.tolist()\n",
    "\n",
    "overlap_list = [list(blast_tolist[0])]\n",
    "gene_copies = {overlap_list[-1][1]:1}\n",
    "list_len = len(blast_tolist)\n",
    "for row in range(1,list_len):\n",
    "    last = overlap_list[-1]\n",
    "    nrow = list(blast_tolist[row]) # the new row list\n",
    "    ovl, ovr = (last[5],last[6]) if last[-1]==\"+\" else (last[6],last[5]) #overlap_left/right\n",
    "    rol, ror = (nrow[5],nrow[6]) if nrow[-1]==\"+\" else (nrow[6],nrow[5]) #row_left/right\n",
    "    #print(blast_tolist[row])\n",
    "    if nrow[0] != last[0]:\n",
    "        gene_copies = {nrow[1]:1} # first count of gene_exon copy\n",
    "    \n",
    "    if (nrow[0] == last[0]) & (nrow[4] == last[4]) & (nrow[-1] == last[-1]): # if taxa, chrom, strand equal\n",
    "        #new_name = nrow[1] if ror-rol > ovr-ovl else last[1]  # keep the name of the larger exon\n",
    "        #nrow[1]\n",
    "        #if new_name in gene_copies.keys():\n",
    "        #    gene_copies[new_name] += 1\n",
    "        #    new_name = new_name.split(\"_\")[0]+\".\"+str(gene_copies[new_name])+\"_\"+new_name.split(\"_\")[1]\n",
    "        #else:\n",
    "        #    gene_copies[new_name] = 1\n",
    "        \n",
    "        #if (rol == ovl) & (ror == ovr): # if the blast result is the same add * to the name\n",
    "        #    overlap_list[-1][1] = nrow[1] # if the overlap is equal\n",
    "        if (rol <= ovl) & (ror >= ovr): # if the new blast row spans over then replace with new row completely\n",
    "            overlap_list[-1] = nrow # if the new row spans previous, replace\n",
    "        elif (rol < ovl) & (ror >= ovl) & (ror <= ovr):        \n",
    "            overlap_list[-1][1] = nrow[1]\n",
    "            if nrow[-1] == \"+\":\n",
    "                overlap_list[-1][5] = rol\n",
    "            else:\n",
    "                overlap_list[-1][6] = rol\n",
    "        \n",
    "        elif (ror > ovr) & (rol >= ovl) & (rol <= ovr):\n",
    "            overlap_list[-1][1] = nrow[1]\n",
    "            if nrow[-1] == \"+\":\n",
    "                overlap_list[-1][6] = ror\n",
    "            else:\n",
    "                overlap_list[-1][5] = ror\n",
    "        elif (rol >= ovl) & (ror<=ovr): # if new row is within previous row then skip it\n",
    "            continue\n",
    "        else:\n",
    "            overlap_list.append(nrow)\n",
    "    else:\n",
    "        overlap_list.append(nrow)\n",
    "\n",
    "with open(\"raw_overlap_list.tsv\", \"w\") as overlap_list_out: \n",
    "    for row in overlap_list:\n",
    "        overlap_list_out.write(\"\\t\".join(str(e) for e in row)+\"\\n\")\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following is optional: Add upstream or downstream DNA padding to all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_padding = 0\n",
    "right_padding = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a list of coordinates using relative start site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumed that sorted by 6th column first and then by 1st\n",
    "# the left- and right-most coordinates for each inbred\n",
    "# 'B73': ['chr10', 72947519, 73642747],\n",
    "loci_coord = {} \n",
    "\n",
    "# the left- and right-most coordinates for each gene\n",
    "#'B73': [['PROPEP4', 1, 605], ['PROPEP4b*', 87931, 87980],\n",
    "xlim_coord = {} \n",
    "\n",
    "# the coordinates for each exon, further edited to remove overlaps\n",
    "# 'B73': [['PROPEP4', 'exon1', 1, 605, '-'], ['PROPEP4b*', 'exon1', 87931, 87980, '-'],\n",
    "gene_coord = {} \n",
    "\n",
    "overlap_list_copy = list(overlap_list.copy())\n",
    "\n",
    "### If I run this twice in a row it overwrites overlap_list and I don't know why ###\n",
    "# [[1, 'PROPEP4_exon1', 1, 588, 'chr10', 72948124, 72947519, '-'],\n",
    "last = overlap_list_copy[0]\n",
    "\n",
    "longest_exon_dict = {}\n",
    "for line in overlap_list_copy:\n",
    "    if line[1] not in longest_exon_dict.keys():\n",
    "        longest_exon_dict[line[1]] = line[3]\n",
    "    else:\n",
    "        longest_exon_dict[line[1]] = max(longest_exon_dict[line[1]], line[3])\n",
    "\n",
    "# Create a dictionary, set default val=1, and increment if there are gene duplications in locus\n",
    "copy_dict = defaultdict(lambda: 1)\n",
    "for line in overlap_list_copy:\n",
    "    # Read each line of the overlap list\n",
    "    strand = line[-1]\n",
    "    left = min(int(line[5]), int(line[6]))\n",
    "    right = max(int(line[5]), int(line[6]))\n",
    "    genotype = taxa_dict[str(line[0])]\n",
    "    chromosome = line[4]\n",
    "    \n",
    "    if line[1].split(\"_\")[0] == \"GeneID\":\n",
    "        # Sometimes the splice-sites don't match but it's easy to see it in alignment vs. manually finding the mismatch\n",
    "        if line[2] < 4:\n",
    "            if strand == \"+\":\n",
    "                #print(taxa_dict[str(line[0])], line[1],left)\n",
    "                left = left - line[2] + 1\n",
    "                #print(left)\n",
    "            else:\n",
    "                right = right + line[2] - 1\n",
    "    # Also check splice-site against exon length, if it is 1 or 2 bp shorter than longest one\n",
    "    \n",
    "        if  (longest_exon_dict[line[1]] - line[3]) < 91 and (longest_exon_dict[line[1]] - line[3]) > 0:\n",
    "            # In this specific instance the stop site in some lines was not within the reference gene range\n",
    "            padding = 0\n",
    "            if line[1] == 'GeneID_exon7': \n",
    "                padding = 0\n",
    "            if strand == \"+\":\n",
    "                right = right + longest_exon_dict[line[1]] - line[3] + padding\n",
    "            else:\n",
    "                left = left - (longest_exon_dict[line[1]] - line[3]) - padding\n",
    "        \n",
    "    if len(line[1].split(\"_\")) == 2:\n",
    "        # Get the gene ID and exon number based on query\n",
    "        gene = line[1].split(\"_\")[0].split(\".\")[0]\n",
    "        exon = line[1].split(\"_\")[1]\n",
    "    else:\n",
    "        # Need to check if overlapped blast-hits are renamed to this format\n",
    "        gene = line[1].split(\"_\")[0] + \"_\" + line[1].split(\"_\")[1]\n",
    "        exon = line[1].split(\"_\")[2]\n",
    "    \n",
    "    # Because we assume that the overlap list is sorted, first genotype line is upstream\n",
    "    if genotype not in loci_coord.keys():\n",
    "        # left_loci is the reference upstream genomic coordinate initated once for each genotype\n",
    "        left_loci = left - left_padding\n",
    "        # Start inserting the genomic and relative coordinates to each dictionary\n",
    "        loci_coord[genotype] = [chromosome, left_loci, right + right_padding]\n",
    "        xlim_coord[genotype] = [[gene, 1+left_padding, right-left_loci+left_padding]]\n",
    "        gene_coord[genotype] = [[gene, exon,1+left_padding, right-left_loci+left_padding, strand]]\n",
    "    else:\n",
    "        # Every new loci_coord line extend the right loci, because lines are ordered\n",
    "        loci_coord[genotype][2] = right + right_padding\n",
    "        # Below assumes the duplicate genes are in order\n",
    "        if xlim_coord[genotype][-1][0].split(\".\")[0] == gene: \n",
    "            previous_strand = gene_coord[genotype][-1][-1] # I don't think this does anything\n",
    "            if len(line[1].split(\"_\")) == 2:\n",
    "                # Need to standarize it, if it has exon written in the exon number or not\n",
    "                previous_exon = int(gene_coord[genotype][-1][-4].split(\"exon\")[1])\n",
    "                current_exon = int(exon.split(\"exon\")[1])\n",
    "            else:\n",
    "                previous_exon = int(gene_coord[genotype][-1][-4])\n",
    "                current_exon = int(exon)\n",
    "            # If exons are consecutive, assume that they are part of the same gene and adjust values\n",
    "            # if  ((previous_exon+1==current_exon) and strand==\"+\") or ((previous_exon-1==current_exon) and strand==\"-\"):\n",
    "            if  ((previous_exon<current_exon) and strand==\"+\") or ((previous_exon>current_exon) and strand==\"-\"):\n",
    "                xlim_coord[genotype][-1][2] = right-left_loci+left_padding\n",
    "                gene_coord[genotype][-1].extend([exon, left-left_loci+left_padding, right-left_loci+left_padding, strand])\n",
    "            # Sometimes minor insertions break exons, so if exon names are the same and arbitrary distance is short keep going\n",
    "            elif ((left-left_loci-gene_coord[genotype][-1][-2]) < 5000) & (exon==gene_coord[genotype][-1][-4].split(\"_\")[-1]): \n",
    "                xlim_coord[genotype][-1][2] = right-left_loci+left_padding\n",
    "                gene_coord[genotype][-1].extend([exon, left-left_loci+left_padding, right-left_loci+left_padding, strand])\n",
    "            # Else, assume this is a new duplicate gene\n",
    "            else: \n",
    "                copy_dict[(genotype,gene,)] += 1\n",
    "                gene = gene+\".\"+str(copy_dict[(genotype,gene,)])\n",
    "                xlim_coord[genotype].append([gene, left-left_loci+left_padding, right-left_loci+left_padding])\n",
    "                gene_coord[genotype].append([gene, exon, left-left_loci+left_padding, right-left_loci+left_padding, strand])            \n",
    "        else:\n",
    "            xlim_coord[genotype].append([gene, left-left_loci+left_padding, right-left_loci+left_padding])\n",
    "            gene_coord[genotype].append([gene, exon, left-left_loci+left_padding, right-left_loci+left_padding, strand])\n",
    "for key in gene_coord[\"B73\"]:\n",
    "    print(key[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" You can also manually replace some properties if it's too much work to get to work\n",
    "\"\"\"\n",
    "\n",
    "gene_coord[\"CML69\"] = [['PROPEP4', 'exon1', 1, 599, '-'], \n",
    "['PROPEP4.2', 'exon1', 14203, 14441, '-'], \n",
    "['PROPEP4.3', 'exon1', 15211, 15819, '-'],\n",
    "['PROPEP4.4', 'exon1', 42244, 42370, '-'],\n",
    "['PROPEP5', 'exon1', 66134, 66580, '-']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the genomic sequence for each line. Change `skip = False` to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skip = True\n",
    "\n",
    "with open('fasta_loci/combined.fasta', 'w') as fp: \n",
    "    pass\n",
    "fp.close()\n",
    "# https://stackoverflow.com/questions/1429556/command-to-get-nth-line-of-stdout\n",
    "\n",
    "with open('coordinate_list.tsv', 'w') as fp: \n",
    "    pass\n",
    "fp.close()\n",
    "\n",
    "#count = 0\n",
    "coordinate_list = open(\"coordinate_list.tsv\",'w')\n",
    "for genotype, coords in loci_coord.items():\n",
    "    if skip: break\n",
    "    chromosome, left, right = coords[0], coords[1], coords[2]\n",
    "    #print(genotype,chromosome, left, right, identity_dict[(genotype,chromosome)], str(left), str(right))\n",
    "    #print('blastdbcmd -db ../../FASTA/BLASTdb/'+genotype+'.db -entry \"'+identity_dict[(genotype,chromosome)]+'\" -range \"'+str(left)+'-'+str(right)+'\" -strand plus -line_length 1000000000| sed 1d  >> fasta_loci/combined.fasta')\n",
    "    coordinate_list.write(\"\\t\".join([genotype,chromosome,str(left),str(right)])+\"\\n\")\n",
    "    os.system('echo \">' + genotype + '\" >> fasta_loci/combined.fasta')\n",
    "    os.system('blastdbcmd -db ../../FASTA/BLASTdb/'+genotype+'.db -entry \"'+identity_dict[(genotype,chromosome)]+'\" -range \"'+str(left)+'-'+str(right)+'\" -strand plus -line_length 1000000000| sed 1d  >> fasta_loci/combined.fasta')\n",
    "    #print(os.path.getsize(\"combined.fasta\"))            \n",
    "    #count += 1\n",
    "    #if count ==2:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to make a custom_loci directory\n",
    "\n",
    "for genotype, genes in gene_coord.items():\n",
    "    if os.path.exists(\"custom_loci/custom_loci_\"+genotype+\".csv\"):\n",
    "        os.remove(\"custom_loci/custom_loci_\"+genotype+\".csv\")\n",
    "    count = 1\n",
    "    with open(\"custom_loci/custom_loci_\"+genotype+\".csv\", 'a') as custom_loci:\n",
    "        custom_loci.write(\",name,feature,start,end,strand\\n\")\n",
    "        for gene in genes:\n",
    "            name,exon,left,right,strand = gene[0],gene[1],gene[2],gene[-2],gene[4]\n",
    "            if name == \"PROPEP4\":\n",
    "                name = \"PROPEP4.1\"\n",
    "            custom_loci.write(\",\".join([str(count),name,\"mRNA\",str(left),str(right),strand])+\"\\n\")\n",
    "            count+=1\n",
    "            for exon_count in range(int((len(gene)-1)/4)):\n",
    "                exon,left,right,strand = gene[1+4*exon_count:5+4*exon_count]\n",
    "                custom_loci.write(\",\".join([str(count),exon,\"exon\",str(left),str(right),strand])+\"\\n\")\n",
    "                count+=1\n",
    "                #print(exon_count)\n",
    "            #print(gene_coord[\"B73\"][2][1:][::4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assigned_xlims.csv', 'w') as delete: \n",
    "    pass\n",
    "delete.close()\n",
    "\n",
    "with open('assigned_xlims.csv', 'a') as xlims_out:\n",
    "    xlims_out.write(\"genotype,left,right\\n\")\n",
    "    for genotype, xlims in xlim_coord.items():\n",
    "        for xlim in xlims:\n",
    "            xlims_out.write(genotype+\",\"+str(xlim[1])+\",\"+str(xlim[2])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A fasta parser to save all gene CDS sequences based on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDS_genes = OrderedDict()\n",
    "CDS_inbreds = {}\n",
    "add_id_to_inbred_name = True\n",
    "\n",
    "#Rename variable. The combined.fasta contains all the full DNA seqs for each inbred\n",
    "# TODO: Implement parsing using biopython SeqIO instead of python text IO parser\n",
    "# Assumed fasta sequence for each value is on a single line\n",
    "coordinate_list = open(\"fasta_loci/combined.fasta\",'r')\n",
    "for row in coordinate_list:\n",
    "    # Iterate over fasta file and save inbred name and sequence in temps\n",
    "    if row[0] == \">\":\n",
    "        temp_inbred = row[1:-1] # skips the linebreak\n",
    "        continue\n",
    "    else:\n",
    "        temp_seq = row[:-1] # skips the linebreak\n",
    "    \n",
    "    # Open the speicific inbred file\n",
    "    with open(\"custom_loci/custom_loci_\"+temp_inbred+\".csv\", 'r') as loci:\n",
    "        # Prase the custom loci file for each gene\n",
    "        skip = True\n",
    "        temp_CDS = '' \n",
    "        for loc in loci:\n",
    "            if skip == True: skip = False ; continue # skip the first line\n",
    "            loc = loc.strip().split(\",\")\n",
    "            # if the line is mRNA then\n",
    "            if loc[2]==\"mRNA\":\n",
    "                # if the temp_CDS is not empty and mRNA means we are done with parsing\n",
    "                # the previous gene and that we can add the combined CDS to the dictionary\n",
    "                if temp_CDS != '':\n",
    "                    # Save the sequence to the  CDS_genes dict file to write later\n",
    "                    CDS_genes.update({temp_gene:temp_CDS})\n",
    "                    # If the gene ID is not in dict, start a new key with avaialble\n",
    "                    if temp_gene not in CDS_inbreds.keys():\n",
    "                        CDS_inbreds[temp_gene] = OrderedDict({temp_inbred_id:temp_CDS})\n",
    "                    # Not sure why, or if, this else statement is needed, could add a print command\n",
    "                    # Maybe it is for reverse-complement sequences?\n",
    "                    else:\n",
    "                        CDS_inbreds[temp_gene].update({temp_inbred_id:temp_CDS})\n",
    "                temp_gene = loc[1]\n",
    "                # A boolean of wether to add gene ID to inbred ID. One of the outputs is a fasta\n",
    "                # file of all CDS sequences for each inbred, and easier to handle if it has built-in ID\n",
    "                # of both gene and inbred. Alternatively, could be save as just inbred name\n",
    "                if add_id_to_inbred_name:\n",
    "                    temp_inbred_id = temp_inbred+\"_\"+temp_gene\n",
    "                else:\n",
    "                    temp_inbred_id = temp_inbred\n",
    "                    \n",
    "                temp_gene = loc[1]\n",
    "                temp_CDS = ''\n",
    "            \n",
    "            # When iterating over exons (aka not mRNA) write the DNA sequence to CDS seq\n",
    "            elif loc[-1]==\"+\":\n",
    "                if loc[3]==\"1\": loc[3]=0 # xlims start with 1 instead of 0, but other coordinates correct\n",
    "                temp_CDS += temp_seq[int(loc[3]):int(loc[4])+1]\n",
    "            elif loc[-1]==\"-\":\n",
    "                if loc[3]==\"1\": loc[3]=0 # xlims start with 1 instead of 0, but other coordinates correct\n",
    "                temp_CDS = str(Seq(temp_seq[int(loc[3]):int(loc[4])+1]).reverse_complement()) + temp_CDS\n",
    "        \n",
    "        # Since the last line is not mRNA need to manually add the last gene\n",
    "        # Copied that from above to add the last gene\n",
    "        CDS_genes.update({temp_gene:temp_CDS})\n",
    "        if temp_gene not in CDS_inbreds.keys():\n",
    "            CDS_inbreds[temp_gene] = OrderedDict({temp_inbred_id:temp_CDS})\n",
    "        else:\n",
    "            CDS_inbreds[temp_gene].update({temp_inbred_id:temp_CDS})\n",
    "    \n",
    "    with open(\"custom_CDS/inbreds/\"+temp_inbred+\".fasta\", \"w\") as inbred_CDS:\n",
    "        for key, val in CDS_genes.items():\n",
    "            inbred_CDS.write(\">\"+key+\"\\n\")\n",
    "            inbred_CDS.write(val+\"\\n\")\n",
    "\n",
    "# This has to be written after all inbred sequences were collected            \n",
    "for gene, gene_dict in CDS_inbreds.items():\n",
    "    with open(\"custom_CDS/genes/\"+gene+\".fasta\", \"w\") as genes_CDS:\n",
    "        for key, val in gene_dict.items():\n",
    "            genes_CDS.write(\">\"+key+\"\\n\")\n",
    "            genes_CDS.write(val+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A fasta parser to save all gene integenic sequences based on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(project_name+\"/\")\n",
    "intergenic_genes = OrderedDict()\n",
    "intergenic_inbreds = {}\n",
    "\n",
    "add_id_to_inbred_name = False\n",
    "\n",
    "# Rename variable. The combined.fasta contains all the full DNA seqs for each inbred\n",
    "# TODO: Implement parsing using biopython SeqIO instead of python text IO parser\n",
    "# Assumed fasta sequence for each value is on a single line\n",
    "coordinate_list = open(\"fasta_loci/combined.fasta\",'r')\n",
    "for row in coordinate_list:\n",
    "    # Iterate over fasta file and save inbred name and sequence in temps\n",
    "    if row[0] == \">\":\n",
    "        temp_inbred = row[1:-1] # skips the linebreak\n",
    "        continue\n",
    "    else:\n",
    "        temp_seq = row[:-1] # skips the linebreak\n",
    "    \n",
    "    intergeneic_coordinates_list = []\n",
    "    intergeneic_genes_list = []\n",
    "    # Open the speicific inbred file\n",
    "    with open(\"custom_loci/custom_loci_\"+temp_inbred+\".csv\", 'r') as loci:\n",
    "        # Prase the custom loci file for each gene\n",
    "        skip = True\n",
    "        temp_CDS = '' \n",
    "        for loc in loci:\n",
    "            if skip == True: skip = False ; continue # skip the first line\n",
    "            loc = loc.strip().split(\",\")\n",
    "            # if the line is mRNA then\n",
    "            if loc[2]==\"mRNA\":\n",
    "                # To get intergenic regions we just get the start end site of each mRNA\n",
    "                # and append to list. For the time being, assume coordinate [0] is skippable\n",
    "                intergeneic_coordinates_list.append(int(loc[3]))  # gene start\n",
    "                intergeneic_coordinates_list.append(int(loc[4]))  # gene end\n",
    "                intergeneic_genes_list.append(loc[1])             # gene ID\n",
    "                \n",
    "        for i in range(1, len(intergeneic_genes_list)):\n",
    "            # Skipped the first and last coordinate_list to get the start and end of each pair of genes\n",
    "            temp_intergenic = temp_seq[intergeneic_coordinates_list[i*2-1]+1:intergeneic_coordinates_list[i*2]]\n",
    "            intergenic_genes.update({intergeneic_genes_list[i]:temp_intergenic})\n",
    "            # A boolean of wether to add gene ID to inbred ID. One of the outputs is a fasta\n",
    "            # file of all CDS sequences for each inbred, and easier to handle if it has built-in ID\n",
    "            # of both gene and inbred. Alternatively, could be save as just inbred name\n",
    "            \n",
    "            if add_id_to_inbred_name:\n",
    "                temp_inbred_id = temp_inbred+\"_\"+intergeneic_genes_list[i]\n",
    "            else:\n",
    "                temp_inbred_id = temp_inbred\n",
    "            # Once we have the temporary inbred_id either with gene or without, add to dict\n",
    "            if intergeneic_genes_list[i] not in intergenic_inbreds.keys():\n",
    "                intergenic_inbreds[intergeneic_genes_list[i]] = OrderedDict({temp_inbred_id:temp_intergenic})\n",
    "            else:\n",
    "                intergenic_inbreds[intergeneic_genes_list[i]].update({temp_inbred_id:temp_intergenic})\n",
    "    \n",
    "    with open(\"custom_intergenic/inbreds/\"+temp_inbred+\".fasta\", \"w\") as inbred_CDS:\n",
    "        for key, val in intergenic_genes.items():\n",
    "            inbred_CDS.write(\">\"+key+\"\\n\")\n",
    "            inbred_CDS.write(val+\"\\n\")\n",
    "\n",
    "# This has to be written after all inbred sequences were collected            \n",
    "for gene, gene_dict in intergenic_inbreds.items():\n",
    "    with open(\"custom_intergenic/genes/\"+gene+\".fasta\", \"w\") as genes_CDS:\n",
    "        for key, val in gene_dict.items():\n",
    "            genes_CDS.write(\">\"+key+\"\\n\")\n",
    "            genes_CDS.write(val+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine custom_loci with predicted GRINST TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "# os.chdir(project_name+\"/\")\n",
    "# pathlib.Path(\"custom_TE_loci\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the coordinates for the TEs are based of intergenic starts sites, need to iterate over genes\n",
    "# Iterate over a file list that is based on the GRINST results. File names based on gene infront of intergenic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grinst_list = []\n",
    "for file in os.listdir(\"custom_TE_loci/\"):\n",
    "    if file.split(\"_\")[1] == \"grinst.csv\":\n",
    "        grinst_list.append(file.split(\"_\")[0])\n",
    "print(grinst_list)\n",
    "for file in os.listdir(\"custom_loci/\"):\n",
    "    if file.split(\".\")[-1] != \"csv\": continue\n",
    "    #if file != \"custom_loci_M162W.csv\": break # just for testing\n",
    "    temp_inbred = file.split(\".\")[0].split(\"_\")[-1]\n",
    "    # This will be the new custom TE loci file to writeline into\n",
    "    f = open(\"custom_TE_loci/custom_loci_\"+temp_inbred+\".csv\", \"a\")\n",
    "    f.write(\",name,feature,start,end,strand\\n\")\n",
    "    # Start parsing original custom_loci file for each inbred\n",
    "    with open(\"custom_loci/custom_loci_\"+temp_inbred+\".csv\", 'r') as loci:\n",
    "    # Parse the custom loci file for each gene and keep track of the mRNA end\n",
    "    # For each mRNA encounter, parse the grinst list and check if matches\n",
    "    # If grinst matches mRNA, using the end of the previous mRNA end to offset\n",
    "        \n",
    "        line_count = 1\n",
    "        skip = True\n",
    "        list_gene_id, list_end_coord = [], []\n",
    "        for loc in loci:\n",
    "            if skip == True: skip = False ; continue # skip the first line\n",
    "            loc = loc.strip().split(\",\")\n",
    "            if loc[2]==\"mRNA\":\n",
    "                list_gene_id.append(loc[1])\n",
    "                list_end_coord.append(loc[4])\n",
    "                for grinst in grinst_list:\n",
    "                    if grinst==list_gene_id[-1]:\n",
    "                        offset = int(list_end_coord[-2])\n",
    "                        # Start parsing the grinst TE file\n",
    "                        with open(\"custom_TE_loci/\"+grinst+\"_grinst.csv\", 'r') as TEs:\n",
    "                            skip = True\n",
    "                            for te in TEs:\n",
    "                                if skip == True: skip = False ; continue # skip the first line\n",
    "                                te = te.strip().split(\",\")\n",
    "                                if te[0] != temp_inbred: continue\n",
    "                                ostart, oend = str(int(te[1]) + offset), str(int(te[2]) + offset)\n",
    "                                write_list = [str(line_count), te[6], \"mRNA\", ostart, oend, \"+\"]\n",
    "                                f.writelines(\",\".join(write_list)+\"\\n\")\n",
    "                                line_count += 1\n",
    "                                write_list = [str(line_count), te[6], \"exon\", ostart, oend, \"+\"]\n",
    "                                f.writelines(\",\".join(write_list)+\"\\n\") \n",
    "                                line_count += 1\n",
    "            loc[0] = str(line_count)\n",
    "            f.writelines(\",\".join(loc)+\"\\n\")\n",
    "            line_count += 1 # increase line_count by 1 after each writelines everywhere\n",
    "            print(loc)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
