{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blastdbcmd tutorial\n",
    "#https://blastedbio.blogspot.com/2012/10/my-ids-not-good-enough-for-ncbi-blast.html\n",
    "\n",
    "import os, sys, pathlib\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"gene_name\"\n",
    "chdir = \"/Users/username/syntenyZ\"\n",
    "os.chdir(chdir)\n",
    "pathlib.Path(project_name+\"/\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_loci\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/fasta_loci\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_loci\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_CDS\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_CDS/genes\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_CDS/inbreds\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_intergenic\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_intergenic/genes\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(project_name+\"/custom_intergenic/inbreds\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dictionary with taxa title ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * TODO: Add relevant code and documentation about storing FASTA as blastdb *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary of the taxa ID csv based on the blast DB based on a custom csv file\n",
    "# For each taxa ID returns a dictionaty key:val like this: '1': 'B73', '2': 'W22' ... \n",
    "taxa_dict = {}\n",
    "title2taxa = open(\"../FASTA/title2taxa.csv\",\"r\")\n",
    "for line in title2taxa:\n",
    "    line = line.strip().split(\",\") # strip remove \\n from the end\n",
    "    taxa_dict[line[1]] = line[0]   # add the lines as a new dicrionary element\n",
    "# I don't know why it started adding wrong UNICODE encoding to B73 ('\\ufeffB73')\n",
    "# TODO: Figure out if this is a consistent problem across different OSes\n",
    "taxa_dict[\"1\"] = \"B73\"\n",
    "taxa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BlastDB doesn't retain the origin chromsome numbers so I manually made a conversion list\n",
    "# returns a dict like this: 'B73', 'Chr10'): 'gnl|BL_ORD_ID|0', ('B73', 'Chr1'): 'gnl|BL_ORD_ID|1' ...\n",
    "\n",
    "# I don't know why it started adding wrong UNICODE encoding to B73 ('\\ufeffB73')\n",
    "count = 0\n",
    "\n",
    "identity_dict = {}\n",
    "chr2identity = open(\"../FASTA/chr2identity.csv\",\"r\")\n",
    "for line in chr2identity:\n",
    "    if count==0:\n",
    "        identity_dict[(\"title\",\"chr\",)] = \"identity\" # add values to tuple keys\n",
    "    else:\n",
    "        line = line.strip().split(\",\")            # strip remove \\n from the end\n",
    "        identity_dict[tuple(line[0:2])] = line[2] # add values to tuple keys\n",
    "    count += 1\n",
    "identity_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run blast on specified genomes using the query.fasta in the project file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../FASTA/BLASTdb/\")\n",
    "# Before running blastn to get target hits, make sure that you have the query.fasta file in your project folder\n",
    "print(\"Changed directory to:\", os.getcwd())\n",
    "os.system('blastn -db \"B73.db W22.db Mo17.db B97.db CML52.db CML103.db CML228.db CML247.db CML277.db CML322.db CML333.db CML69.db EP1.db F7.db HP301.db Il14H.db Ki11.db Ki3.db Ky21.db M162W.db M37W.db Mo18W.db Ms71.db NC350.db NC358.db Oh43.db Oh7B.db P39.db Tx303.db Tzi8.db PI566673.db\" -query ../../syntenyZ/'+project_name+'/query.fasta -out ../../syntenyZ/'+project_name+'/blast_results.tsv -num_threads 4 -evalue 1e-4 -outfmt \"6 staxid qseqid qstart qend sseqid sstart send\"')\n",
    "os.chdir(\"../../syntenyZ/\"+project_name+\"/\")\n",
    "print(\"Changed directory back to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before continuing, filter the blast results to contain only wanted rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(project_name+\"/\") # Use this if you already ran the previous steps\n",
    "blast_df = pd.read_table(\"blast_results.tsv\", header=None, names=[\"taxa\",\"ref\", \"qs\",\"qe\",\"chr\",\"ss\",\"se\"])\n",
    "blast_df['strand'] = blast_df[['ss','se']].apply(lambda x: \"+\" if x['ss']<x['se'] else \"-\", axis=1)\n",
    "#blast_df = blast_df[blast_df[\"taxa\"]==1]\n",
    "blast_tolist = blast_df.sort_values(['taxa', 'chr', 'ss',], ascending=[True, True, True]).values.tolist()\n",
    "\n",
    "overlap_list = [list(blast_tolist[0])]\n",
    "gene_copies = {overlap_list[-1][1]:1}\n",
    "list_len = len(blast_tolist)\n",
    "for row in range(1,list_len):\n",
    "    last = overlap_list[-1]\n",
    "    nrow = list(blast_tolist[row]) # the new row list\n",
    "    ovl, ovr = (last[5],last[6]) if last[-1]==\"+\" else (last[6],last[5]) #overlap_left/right\n",
    "    rol, ror = (nrow[5],nrow[6]) if nrow[-1]==\"+\" else (nrow[6],nrow[5]) #row_left/right\n",
    "    #print(blast_tolist[row])\n",
    "    if nrow[0] != last[0]:\n",
    "        gene_copies = {nrow[1]:1} # first count of gene_exon copy\n",
    "    \n",
    "    if (nrow[0] == last[0]) & (nrow[4] == last[4]) & (nrow[-1] == last[-1]): # if taxa, chrom, strand equal\n",
    "        #new_name = nrow[1] if ror-rol > ovr-ovl else last[1]  # keep the name of the larger exon\n",
    "        #nrow[1]\n",
    "        #if new_name in gene_copies.keys():\n",
    "        #    gene_copies[new_name] += 1\n",
    "        #    new_name = new_name.split(\"_\")[0]+\".\"+str(gene_copies[new_name])+\"_\"+new_name.split(\"_\")[1]\n",
    "        #else:\n",
    "        #    gene_copies[new_name] = 1\n",
    "        \n",
    "        #if (rol == ovl) & (ror == ovr): # if the blast result is the same add * to the name\n",
    "        #    overlap_list[-1][1] = nrow[1] # if the overlap is equal\n",
    "        if (rol <= ovl) & (ror >= ovr): # if the new blast row spans over then replace with new row completely\n",
    "            overlap_list[-1] = nrow # if the new row spans previous, replace\n",
    "        elif (rol < ovl) & (ror >= ovl) & (ror <= ovr):        \n",
    "            overlap_list[-1][1] = nrow[1]\n",
    "            if nrow[-1] == \"+\":\n",
    "                overlap_list[-1][5] = rol\n",
    "            else:\n",
    "                overlap_list[-1][6] = rol\n",
    "        \n",
    "        elif (ror > ovr) & (rol >= ovl) & (rol <= ovr):\n",
    "            overlap_list[-1][1] = nrow[1]\n",
    "            if nrow[-1] == \"+\":\n",
    "                overlap_list[-1][6] = ror\n",
    "            else:\n",
    "                overlap_list[-1][5] = ror\n",
    "        elif (rol >= ovl) & (ror<=ovr): # if new row is within previous row then skip it\n",
    "            continue\n",
    "        else:\n",
    "            overlap_list.append(nrow)\n",
    "    else:\n",
    "        overlap_list.append(nrow)\n",
    "\n",
    "with open(\"raw_overlap_list.tsv\", \"w\") as overlap_list_out: \n",
    "    for row in overlap_list:\n",
    "        overlap_list_out.write(\"\\t\".join(str(e) for e in row)+\"\\n\")\n",
    "        print(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumed that sorted by 6th column first and then by 1st\n",
    "loci_coord = {} \n",
    "# the left- and right-most coordinates for each inbred\n",
    "# 'B73': ['chr10', 72947519, 73642747],\n",
    "xlim_coord = {} \n",
    "# the left- and right-most coordinates for each gene\n",
    "#'B73': [['PROPEP4', 1, 605], ['PROPEP4b*', 87931, 87980],\n",
    "gene_coord = {} \n",
    "# the coordinates for each exon, further edited to remove overlaps\n",
    "# 'B73': [['PROPEP4', 'exon1', 1, 605, '-'], ['PROPEP4b*', 'exon1', 87931, 87980, '-'],\n",
    "left_loci = 0\n",
    "#blast_results = open(\"FACR_16/facr_16_blast.tsv\",\"r\")\n",
    "overlap_list_copy = list(overlap_list.copy())\n",
    "### If I run this twice in a row it overwrites overlap_list and need to check why ###\n",
    "last = overlap_list_copy[0]\n",
    "copy_dict = defaultdict(lambda: 1)\n",
    "for line in overlap_list_copy:\n",
    "    #if line[0]==25:\n",
    "    #    print(line)\n",
    "    strand = line[-1]\n",
    "    left = min(int(line[5]), int(line[6]))\n",
    "    right = max(int(line[5]), int(line[6]))\n",
    "    \n",
    "    genotype = taxa_dict[str(line[0])]\n",
    "    chromosome = line[4]\n",
    "    if len(line[1].split(\"_\")) == 2:\n",
    "        gene = line[1].split(\"_\")[0].split(\".\")[0]\n",
    "        exon = line[1].split(\"_\")[1]\n",
    "    else:\n",
    "        gene = line[1].split(\"_\")[0] + \"_\" + line[1].split(\"_\")[1]\n",
    "        exon = line[1].split(\"_\")[2]\n",
    "    \n",
    "    if genotype not in loci_coord.keys():\n",
    "        left_loci = left\n",
    "        loci_coord[genotype] = [chromosome, left, right]\n",
    "        xlim_coord[genotype] = [[gene, 1, right-left_loci]]\n",
    "        gene_coord[genotype] = [[gene, exon,1, right-left_loci, strand]]\n",
    "    else:    \n",
    "        loci_coord[genotype][2] = right\n",
    "        if xlim_coord[genotype][-1][0].split(\".\")[0] == gene: # below assumes the duplicate genes are in order\n",
    "            previous_strand = gene_coord[genotype][-1][-1]\n",
    "            if len(line[1].split(\"_\")) == 2:\n",
    "                # Need to standarize it if it has exon written in the exon number or not\n",
    "                previous_exon = int(gene_coord[genotype][-1][-4].split(\"exon\")[1])\n",
    "                current_exon = int(exon.split(\"exon\")[1])\n",
    "            else:\n",
    "                previous_exon = int(gene_coord[genotype][-1][-4])\n",
    "                current_exon = int(exon)\n",
    "                \n",
    "            if  ((previous_exon+1==current_exon) and strand==\"+\") or ((previous_exon-1==current_exon) and strand==\"-\"): # if next exon\n",
    "                xlim_coord[genotype][-1][2] = right - left_loci\n",
    "                gene_coord[genotype][-1].extend([exon, left-left_loci, right-left_loci, strand])\n",
    "            elif ((left-left_loci-gene_coord[genotype][-1][-2]) < 1000) & (exon==gene_coord[genotype][-1][-4].split(\"_\")[-1]): # sometimes minor insertions break exons\n",
    "                xlim_coord[genotype][-1][2] = right - left_loci\n",
    "                gene_coord[genotype][-1].extend([exon, left-left_loci, right-left_loci, strand])\n",
    "            else: # assume this is a new duplicate gene\n",
    "                copy_dict[(genotype,gene,)] += 1\n",
    "                gene = gene+\".\"+str(copy_dict[(genotype,gene,)])\n",
    "                xlim_coord[genotype].append([gene, left-left_loci, right-left_loci])\n",
    "                gene_coord[genotype].append([gene, exon, left-left_loci, right-left_loci, strand])            \n",
    "        else:\n",
    "            xlim_coord[genotype].append([gene, left-left_loci, right-left_loci])\n",
    "            gene_coord[genotype].append([gene, exon, left-left_loci, right-left_loci, strand])\n",
    "for key in gene_coord[\"B73\"]:\n",
    "    print(key[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('fasta_loci/combined.fasta', 'w') as fp: \n",
    "    pass\n",
    "fp.close()\n",
    "# https://stackoverflow.com/questions/1429556/command-to-get-nth-line-of-stdout\n",
    "\n",
    "with open('coordinate_list.tsv', 'w') as fp: \n",
    "    pass\n",
    "fp.close()\n",
    "\n",
    "coordinate_list = open(\"coordinate_list.tsv\",'w')\n",
    "for genotype, coords in loci_coord.items():\n",
    "    chromosome, left, right = coords[0], coords[1], coords[2]\n",
    "    coordinate_list.write(\"\\t\".join([genotype,chromosome,str(left),str(right)])+\"\\n\")\n",
    "    os.system('echo \">' + genotype + '\" >> fasta_loci/combined.fasta')\n",
    "    os.system('blastdbcmd -db ../../FASTA/BLASTdb/'+genotype+'.db -entry \"'+identity_dict[(genotype,chromosome)]+'\" -range \"'+str(left)+'-'+str(right)+'\" -strand plus -line_length 1000000000| sed 1d  >> fasta_loci/combined.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genotype, genes in gene_coord.items():\n",
    "    if os.path.exists(\"custom_loci/custom_loci_\"+genotype+\".csv\"):\n",
    "        os.remove(\"custom_loci/custom_loci_\"+genotype+\".csv\")\n",
    "    count = 1\n",
    "    with open(\"custom_loci/custom_loci_\"+genotype+\".csv\", 'a') as custom_loci:\n",
    "        custom_loci.write(\",name,feature,start,end,strand\\n\")\n",
    "        for gene in genes:\n",
    "            name,exon,left,right,strand = gene[0],gene[1],gene[2],gene[-2],gene[4]\n",
    "            if name == \"PROPEP4\":\n",
    "                name = \"PROPEP4.1\"\n",
    "            custom_loci.write(\",\".join([str(count),name,\"mRNA\",str(left),str(right),strand])+\"\\n\")\n",
    "            count+=1\n",
    "            for exon_count in range(int((len(gene)-1)/4)):\n",
    "                exon,left,right,strand = gene[1+4*exon_count:5+4*exon_count]\n",
    "                custom_loci.write(\",\".join([str(count),exon,\"exon\",str(left),str(right),strand])+\"\\n\")\n",
    "                count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assigned_xlims.csv', 'w') as delete: \n",
    "    pass\n",
    "delete.close()\n",
    "\n",
    "with open('assigned_xlims.csv', 'a') as xlims_out:\n",
    "    xlims_out.write(\"genotype,left,right\\n\")\n",
    "    for genotype, xlims in xlim_coord.items():\n",
    "        for xlim in xlims:\n",
    "            xlims_out.write(genotype+\",\"+str(xlim[1])+\",\"+str(xlim[2])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A fasta parser to save all gene CDS sequences based on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDS_genes = OrderedDict()\n",
    "CDS_inbreds = {}\n",
    "add_id_to_inbred_name = True\n",
    "\n",
    "# Rename variable. The combined.fasta contains all the full DNA seqs for each inbred\n",
    "# TODO: Implement parsing using biopython SeqIO instead of python text IO parser\n",
    "# Assumed fasta sequence for each value is on a single line\n",
    "coordinate_list = open(\"fasta_loci/combined.fasta\",'r')\n",
    "for row in coordinate_list:\n",
    "    # Iterate over fasta file and save inbred name and sequence in temps\n",
    "    if row[0] == \">\":\n",
    "        temp_inbred = row[1:-1] # skips the linebreak\n",
    "        continue\n",
    "    else:\n",
    "        temp_seq = row[:-1] # skips the linebreak\n",
    "    \n",
    "    # Open the speicific inbred file\n",
    "    with open(\"custom_loci/custom_loci_\"+temp_inbred+\".csv\", 'r') as loci:\n",
    "        # Prase the custom loci file for each gene\n",
    "        skip = True\n",
    "        temp_CDS = '' \n",
    "        for loc in loci:\n",
    "            if skip == True: skip = False ; continue # skip the first line\n",
    "            loc = loc.strip().split(\",\")\n",
    "            # if the line is mRNA then\n",
    "            if loc[2]==\"mRNA\":\n",
    "                # if the temp_CDS is not empty and mRNA means we are done with parsing\n",
    "                # the previous gene and that we can add the combined CDS to the dictionary\n",
    "                if temp_CDS != '':\n",
    "                    # Save the sequence to the  CDS_genes dict file to write later\n",
    "                    CDS_genes.update({temp_gene:temp_CDS})\n",
    "                    # If the gene ID is not in dict, start a new key with avaialble\n",
    "                    if temp_gene not in CDS_inbreds.keys():\n",
    "                        CDS_inbreds[temp_gene] = OrderedDict({temp_inbred_id:temp_CDS})\n",
    "                    # Not sure why, or if, this else statement is needed, could add a print command\n",
    "                    # Maybe it is for reverse-complement sequences?\n",
    "                    else:\n",
    "                        CDS_inbreds[temp_gene].update({temp_inbred_id:temp_CDS})\n",
    "                temp_gene = loc[1]\n",
    "                # A boolean of wether to add gene ID to inbred ID. One of the outputs is a fasta\n",
    "                # file of all CDS sequences for each inbred, and easier to handle if it has built-in ID\n",
    "                # of both gene and inbred. Alternatively, could be save as just inbred name\n",
    "                if add_id_to_inbred_name:\n",
    "                    temp_inbred_id = temp_inbred+\"_\"+temp_gene\n",
    "                else:\n",
    "                    temp_inbred_id = temp_inbred\n",
    "                    \n",
    "                temp_gene = loc[1]\n",
    "                temp_CDS = ''\n",
    "            \n",
    "            # When iterating over exons (aka not mRNA) write the DNA sequence to CDS seq\n",
    "            elif loc[-1]==\"+\":\n",
    "                if loc[3]==\"1\": loc[3]=0 # xlims start with 1 instead of 0, but other coordinates correct\n",
    "                temp_CDS += temp_seq[int(loc[3]):int(loc[4])+1]\n",
    "            elif loc[-1]==\"-\":\n",
    "                if loc[3]==\"1\": loc[3]=0 # xlims start with 1 instead of 0, but other coordinates correct\n",
    "                temp_CDS = str(Seq(temp_seq[int(loc[3]):int(loc[4])+1]).reverse_complement()) + temp_CDS\n",
    "        \n",
    "        # Since the last line is not mRNA need to manually add the last gene\n",
    "        # Copied that from above to add the last gene\n",
    "        CDS_genes.update({temp_gene:temp_CDS})\n",
    "        if temp_gene not in CDS_inbreds.keys():\n",
    "            CDS_inbreds[temp_gene] = OrderedDict({temp_inbred_id:temp_CDS})\n",
    "        else:\n",
    "            CDS_inbreds[temp_gene].update({temp_inbred_id:temp_CDS})\n",
    "    \n",
    "    with open(\"custom_CDS/inbreds/\"+temp_inbred+\".fasta\", \"w\") as inbred_CDS:\n",
    "        for key, val in CDS_genes.items():\n",
    "            inbred_CDS.write(\">\"+key+\"\\n\")\n",
    "            inbred_CDS.write(val+\"\\n\")\n",
    "\n",
    "# This has to be written after all inbred sequences were collected            \n",
    "for gene, gene_dict in CDS_inbreds.items():\n",
    "    with open(\"custom_CDS/genes/\"+gene+\".fasta\", \"w\") as genes_CDS:\n",
    "        for key, val in gene_dict.items():\n",
    "            genes_CDS.write(\">\"+key+\"\\n\")\n",
    "            genes_CDS.write(val+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A fasta parser to save all gene integenic sequences based on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(project_name+\"/\")\n",
    "intergenic_genes = OrderedDict()\n",
    "intergenic_inbreds = {}\n",
    "\n",
    "add_id_to_inbred_name = False\n",
    "\n",
    "# Rename variable. The combined.fasta contains all the full DNA seqs for each inbred\n",
    "# TODO: Implement parsing using biopython SeqIO instead of python text IO parser\n",
    "# Assumed fasta sequence for each value is on a single line\n",
    "coordinate_list = open(\"fasta_loci/combined.fasta\",'r')\n",
    "for row in coordinate_list:\n",
    "    # Iterate over fasta file and save inbred name and sequence in temps\n",
    "    if row[0] == \">\":\n",
    "        temp_inbred = row[1:-1] # skips the linebreak\n",
    "        continue\n",
    "    else:\n",
    "        temp_seq = row[:-1] # skips the linebreak\n",
    "    \n",
    "    intergeneic_coordinates_list = []\n",
    "    intergeneic_genes_list = []\n",
    "    # Open the speicific inbred file\n",
    "    with open(\"custom_loci/custom_loci_\"+temp_inbred+\".csv\", 'r') as loci:\n",
    "        # Prase the custom loci file for each gene\n",
    "        skip = True\n",
    "        temp_CDS = '' \n",
    "        for loc in loci:\n",
    "            if skip == True: skip = False ; continue # skip the first line\n",
    "            loc = loc.strip().split(\",\")\n",
    "            # if the line is mRNA then\n",
    "            if loc[2]==\"mRNA\":\n",
    "                # To get intergenic regions we just get the start end site of each mRNA\n",
    "                # and append to list. For the time being, assume coordinate [0] is skippable\n",
    "                intergeneic_coordinates_list.append(int(loc[3]))  # gene start\n",
    "                intergeneic_coordinates_list.append(int(loc[4]))  # gene end\n",
    "                intergeneic_genes_list.append(loc[1])             # gene ID\n",
    "                \n",
    "        for i in range(1, len(intergeneic_genes_list)):\n",
    "            # Skipped the first and last coordinate_list to get the start and end of each pair of genes\n",
    "            temp_intergenic = temp_seq[intergeneic_coordinates_list[i*2-1]+1:intergeneic_coordinates_list[i*2]]\n",
    "            intergenic_genes.update({intergeneic_genes_list[i]:temp_intergenic})\n",
    "            # A boolean of wether to add gene ID to inbred ID. One of the outputs is a fasta\n",
    "            # file of all CDS sequences for each inbred, and easier to handle if it has built-in ID\n",
    "            # of both gene and inbred. Alternatively, could be save as just inbred name\n",
    "            \n",
    "            if add_id_to_inbred_name:\n",
    "                temp_inbred_id = temp_inbred+\"_\"+intergeneic_genes_list[i]\n",
    "            else:\n",
    "                temp_inbred_id = temp_inbred\n",
    "            # Once we have the temporary inbred_id either with gene or without, add to dict\n",
    "            if intergeneic_genes_list[i] not in intergenic_inbreds.keys():\n",
    "                intergenic_inbreds[intergeneic_genes_list[i]] = OrderedDict({temp_inbred_id:temp_intergenic})\n",
    "            else:\n",
    "                intergenic_inbreds[intergeneic_genes_list[i]].update({temp_inbred_id:temp_intergenic})\n",
    "    \n",
    "    with open(\"custom_intergenic/inbreds/\"+temp_inbred+\".fasta\", \"w\") as inbred_CDS:\n",
    "        for key, val in intergenic_genes.items():\n",
    "            inbred_CDS.write(\">\"+key+\"\\n\")\n",
    "            inbred_CDS.write(val+\"\\n\")\n",
    "\n",
    "# This has to be written after all inbred sequences were collected            \n",
    "for gene, gene_dict in intergenic_inbreds.items():\n",
    "    with open(\"custom_intergenic/genes/\"+gene+\".fasta\", \"w\") as genes_CDS:\n",
    "        for key, val in gene_dict.items():\n",
    "            genes_CDS.write(\">\"+key+\"\\n\")\n",
    "            genes_CDS.write(val+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine custom_loci with predicted GRINST TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
